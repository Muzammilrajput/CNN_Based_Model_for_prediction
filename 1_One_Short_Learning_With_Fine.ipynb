{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-One_Short_Learning_With_Fine",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpT18W7Ggl4b",
        "colab_type": "code",
        "outputId": "0560c467-dc4b-4cff-bf64-49b882f3f3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6kpwRVpgrP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import imageio\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras \n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhW9_F0ng4mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(2) # Python\n",
        "np.random.seed(1) #numpy\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(3) # Tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re3ghxQHg4_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#The path to the  data\n",
        "root_path = \"./drive/My Drive/DataSet150\"\n",
        "train_path = os.path.join(root_path,'Traning') \n",
        "validation_path = os.path.join(root_path,'Evalution')\n",
        "\n",
        "def load_image(path, n = 0):\n",
        "    X = []\n",
        "    \n",
        "    #Load every alphabet seperately and place that in one tensor\n",
        "    for alphabet in os.listdir(path):\n",
        "#         print(\"Loading Alphabet: \" + alphabet)\n",
        "        alphabet_path = os.path.join(path, alphabet)\n",
        "       \n",
        "        category_images = []\n",
        "            \n",
        "        if not os.path.isdir(alphabet_path):\n",
        "                continue\n",
        "            \n",
        "            #Read evey image with in the directory\n",
        "        for filename in os.listdir(alphabet_path):\n",
        "                image_path = os.path.join(alphabet_path, filename)\n",
        "                image = imageio.imread(image_path)\n",
        "                width = 150\n",
        "                height = 150 # keep original height\n",
        "                dim = (height,width)\n",
        " \n",
        "                # resize image\n",
        "                image = cv2.resize(image, dim)\n",
        "                image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                image= np.expand_dims(image, axis=0)\n",
        "#                 print(image_path)\n",
        "                #Image preprocessing\n",
        "                image = image/255\n",
        "                image = 1 - image\n",
        "                \n",
        "                X.append(image)\n",
        "                \n",
        "        \n",
        "    X = np.stack(X)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTkpt7Stg_nF",
        "colab_type": "code",
        "outputId": "7093bcea-8e03-423a-97c8-1649c9e168ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Loading Training Set\")\n",
        "Xtrain = load_image(train_path)\n",
        "print(Xtrain.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Training Set\n",
            "(801, 1, 150, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_hsas0RhDB-",
        "colab_type": "code",
        "outputId": "7713ddd2-5f7d-4670-cc80-a328220f291f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Now loading evaluation set\")\n",
        "Xval = load_image(validation_path)\n",
        "print(Xval.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now loading evaluation set\n",
            "(764, 1, 150, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBCD3WvBhFRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(data, batch_size):\n",
        "    n_classes, n_examples, h, w = data.shape\n",
        "    \n",
        "    pairs = [np.zeros((batch_size, 1, h, w)) for i in range(2)]\n",
        "    \n",
        "    targets = np.zeros((batch_size,))\n",
        "    targets[batch_size//2:] = 1\n",
        "    \n",
        "    categories = np.random.choice(n_classes, size = (batch_size), replace = False)\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        category = categories[i]\n",
        "        \n",
        "        idx1 = np.random.randint(0, n_examples)\n",
        "        pairs[0][i,:,:,:] = data[category, idx1].reshape(1, h,w)\n",
        "        idx2 = np.random.randint(0, n_examples)\n",
        "        \n",
        "        if targets[i] == 0:\n",
        "            category_2 = category\n",
        "        else:\n",
        "            category_2 = (category + np.random.randint(1, n_classes)) % n_classes\n",
        " \n",
        "        \n",
        "        pairs[1][i,:,:,:] = data[category_2, idx2].reshape(1, h, w)\n",
        "        \n",
        "    return pairs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o92IhAzrjc-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(data,batch_size):\n",
        "        \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
        "        while True:\n",
        "            pairs, targets = get_batch(Xtrain,batch_size)\n",
        "            yield (pairs, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkLAu35jjhp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_oneshot_task(N,data,language=None):\n",
        "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
        "        n_classes, n_examples, w, h = data.shape\n",
        "        indices = np.random.randint(0,n_examples,size=(N,))\n",
        "        categories = np.random.choice(range(n_classes),size=(N,),replace=False)            \n",
        "        true_category = categories[0]\n",
        "        ex1 = np.random.randint(0, n_examples)\n",
        "        ex2 = np.random.randint(0, n_examples)\n",
        "        # ex1, ex2 = np.random.choice(n_examples,replace=False,size=(0,))\n",
        "        test_image = np.asarray([data[true_category,ex1,:,:]]*N).reshape(N, 1, w,h)\n",
        "        support_set = data[categories,indices,:,:]\n",
        "        support_set[0,:,:] = data[true_category,ex2]\n",
        "        support_set = support_set.reshape(N, 1, w,h)\n",
        "        targets = np.zeros((N,))\n",
        "        targets[0] = 1\n",
        "        targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "        pairs = [test_image,support_set]\n",
        "\n",
        "        return pairs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFf8wFM2jk3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_oneshot(model,N,k,data,verbose=0):\n",
        "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
        "        n_correct = 0\n",
        "        if verbose:\n",
        "            print(\"Evaluating model on {} random {} way one-shot learning tasks ...\".format(k,N))\n",
        "        for i in range(k):\n",
        "            inputs, targets = make_oneshot_task(N,data)\n",
        "            probs = model.predict(inputs)\n",
        "            if np.argmax(probs) == np.argmax(targets):\n",
        "                n_correct+=1\n",
        "        percent_correct = (100.0*n_correct / k)\n",
        "        if verbose:\n",
        "            print(\"Got an average of {}% {} way one-shot learning accuracy\".format(percent_correct,N))\n",
        "        return percent_correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyxO8Z4HjrBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, epochs, verbosity):\n",
        "        model.fit_generator(self.generate(batch_size),)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KypD81vxjwbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, Input, Lambda\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3N2Ykfkjzxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Contrastive Loss\n",
        "def euclid_dist(input_pair):\n",
        "    x, y = input_pair\n",
        "    distance = K.sqrt(K.maximum(K.sum(K.square(x - y), axis=-1, keepdims=True), K.epsilon()))\n",
        "    return distance\n",
        "\n",
        "def euclid_dist_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0],1)\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    y_true = -1 * y_true + 1\n",
        "    return K.mean((1-y_true) * K.square(y_pred) + y_true *  K.square(K.maximum(margin - y_pred, 0.0)))\n",
        "\n",
        "def acc(y_true, y_pred):\n",
        "    ones = K.ones_like(y_pred)\n",
        "    return K.mean(K.equal(y_true, ones - K.clip(K.round(y_pred), 0, 1)), axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSZIvvwClfnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS2DGoWxlg-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLhUiuHYj3Q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_width  =150\n",
        "im_height =150\n",
        "im_chan   =1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa9X_V44liEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWr1ZK_Nj78S",
        "colab_type": "code",
        "outputId": "64ac84d8-d289-49b9-d5e5-82386bb4be14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "\n",
        "input_img =Input(( im_chan,im_height,im_width ), name='img')\n",
        "\n",
        "# print(input_img)\n",
        "# Down Block 1\n",
        "c1 = Conv2D(32,(1,1), activation='relu', kernel_regularizer=l2(2e-4) )(input_img)\n",
        "p1 = MaxPooling2D(data_format=\"channels_first\") (c1)\n",
        "\n",
        "#Down Block 2\n",
        "c2 = Conv2D(128, (1, 1), activation='relu', kernel_regularizer=l2(2e-4)) (p1)\n",
        "p2 = MaxPooling2D(data_format=\"channels_first\") (c2)\n",
        "\n",
        "#Down Block 3\n",
        "c3 = Conv2D(128, (1, 1), activation='relu', kernel_regularizer=l2(2e-4)) (p2)\n",
        "p3 = MaxPooling2D(data_format=\"channels_first\") (c3)\n",
        "\n",
        "#Down Block 4\n",
        "c4 = Conv2D(256, (1, 1), activation='relu', kernel_regularizer=l2(2e-4)) (p3)\n",
        "p4 = MaxPooling2D(data_format=\"channels_first\") (c4)\n",
        "# # print(p4)\n",
        "flat = Flatten()(p4)\n",
        "output = Dense(100, activation='sigmoid')(flat)\n",
        "\n",
        "# Instantiate the Model\n",
        "model = Model(input_img, output)\n",
        "\n",
        "input1 = Input(shape = (1,150,150))\n",
        "input2 = Input(shape = (1,150,150))\n",
        "\n",
        "output1 = model(input1)\n",
        "output2 = model(input2)\n",
        "\n",
        "\n",
        "distance = Lambda(euclid_dist, output_shape=euclid_dist_shape)([output1, output2])\n",
        "\n",
        "prediction = Dense(1, activation='sigmoid')(distance)\n",
        "    \n",
        "siamese = Model(inputs=[input1, input2], outputs=prediction)\n",
        "    \n",
        "optimizer = 'adam'\n",
        "    \n",
        "siamese.compile(loss=contrastive_loss, optimizer=optimizer, metrics=[acc])\n",
        "\n",
        "siamese.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_26\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_28 (InputLayer)           (None, 1, 150, 150)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_29 (InputLayer)           (None, 1, 150, 150)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_25 (Model)                (None, 100)          2127524     input_28[0][0]                   \n",
            "                                                                 input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 1)            0           model_25[1][0]                   \n",
            "                                                                 model_25[2][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 1)            2           lambda_12[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,127,526\n",
            "Trainable params: 2,127,526\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH_ahVeFkCOf",
        "colab_type": "code",
        "outputId": "488df888-1f51-4919-bd4a-61279a39fa35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Training loop\n",
        "print(\"!\")\n",
        "evaluate_every = 1 # interval for evaluating on one-shot tasks\n",
        "loss_every=50 # interval for printing loss (iterations)\n",
        "batch_size = 32\n",
        "n_iter = 30\n",
        "N_way = 50 # how many classes for testing one-shot tasks>\n",
        "n_val = 30 #how mahy one-shot tasks to validate on?\n",
        "best = -1\n",
        "weights_path = \"weights\"\n",
        "print(\"training\")\n",
        "for i in range(1, n_iter):\n",
        "    (inputs,targets)=get_batch(Xtrain,batch_size)\n",
        "    loss=siamese.train_on_batch(inputs,targets)\n",
        "    print(loss)\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"evaluating\")\n",
        "        val_acc = test_oneshot(siamese,N_way,n_val,Xval,verbose=True)\n",
        "        if val_acc >= best:\n",
        "            print(\"saving\")\n",
        "            siamese.save(weights_path)\n",
        "            best=val_acc\n",
        "\n",
        "    if i % loss_every == 0:\n",
        "        print(\"iteration {}, training loss: {:.2f},\".format(i,loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\n",
            "training\n",
            "[0.31418765, 0.5]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 100.0% 50 way one-shot learning accuracy\n",
            "saving\n",
            "[0.29304472, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 90.0% 50 way one-shot learning accuracy\n",
            "[0.26938364, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.24972977, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 90.0% 50 way one-shot learning accuracy\n",
            "[0.22977228, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.23263648, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 93.33333333333333% 50 way one-shot learning accuracy\n",
            "[0.21278359, 0.96875]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 100.0% 50 way one-shot learning accuracy\n",
            "saving\n",
            "[0.20211689, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 100.0% 50 way one-shot learning accuracy\n",
            "saving\n",
            "[0.20774525, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.19076745, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.19386111, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.18802434, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.19057688, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 93.33333333333333% 50 way one-shot learning accuracy\n",
            "[0.19867396, 0.96875]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 93.33333333333333% 50 way one-shot learning accuracy\n",
            "[0.18297815, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 100.0% 50 way one-shot learning accuracy\n",
            "saving\n",
            "[0.18623689, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.18139732, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 93.33333333333333% 50 way one-shot learning accuracy\n",
            "[0.18052149, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.17875652, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 86.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.17724161, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.17803708, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 86.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.17510876, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.17397483, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.1778443, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.17160726, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 100.0% 50 way one-shot learning accuracy\n",
            "saving\n",
            "[0.17083646, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 100.0% 50 way one-shot learning accuracy\n",
            "saving\n",
            "[0.1699087, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 90.0% 50 way one-shot learning accuracy\n",
            "[0.16928817, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 96.66666666666667% 50 way one-shot learning accuracy\n",
            "[0.16811746, 1.0]\n",
            "evaluating\n",
            "Evaluating model on 30 random 50 way one-shot learning tasks ...\n",
            "Got an average of 93.33333333333333% 50 way one-shot learning accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaBasaGFkLr-",
        "colab_type": "code",
        "outputId": "0d25c6ad-c3ff-4973-861a-c63a13011017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import backend\n",
        "# force channels-last ordering\n",
        "backend.set_image_data_format('channels_first')\n",
        "print(backend.image_data_format())\n",
        "vgg = VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(3, 150, 150)))\n",
        "\n",
        "# output = vgg.layers[-1].output\n",
        "# output = keras.layers.Flatten()(output)\n",
        "# vgg_model = Model(vgg.input, output)\n",
        "\n",
        "# vgg_model.trainable = False\n",
        "# for layer in vgg_model.layers:\n",
        "#     layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "channels_first\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpdAYznXj7so",
        "colab_type": "code",
        "outputId": "fa25f62d-152f-49f4-87c4-b2cec9f6a4ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "pd.set_option('max_colwidth', -1)\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Layer Type</th>\n",
              "      <th>Layer Name</th>\n",
              "      <th>Layer Trainable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;keras.engine.input_layer.InputLayer object at 0x7f4e83582978&gt;</td>\n",
              "      <td>input_13</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e835823c8&gt;</td>\n",
              "      <td>block1_conv1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e83195eb8&gt;</td>\n",
              "      <td>block1_conv2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f4e831975f8&gt;</td>\n",
              "      <td>block1_pool</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e83198a20&gt;</td>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e831a0198&gt;</td>\n",
              "      <td>block2_conv2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f4e82bf93c8&gt;</td>\n",
              "      <td>block2_pool</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e82c03f60&gt;</td>\n",
              "      <td>block3_conv1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e82c08b00&gt;</td>\n",
              "      <td>block3_conv2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e82c127f0&gt;</td>\n",
              "      <td>block3_conv3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f4e82c208d0&gt;</td>\n",
              "      <td>block3_pool</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e82c2dda0&gt;</td>\n",
              "      <td>block4_conv1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e82c335f8&gt;</td>\n",
              "      <td>block4_conv2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e82bc2438&gt;</td>\n",
              "      <td>block4_conv3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f4e82bcd3c8&gt;</td>\n",
              "      <td>block4_pool</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e82bda898&gt;</td>\n",
              "      <td>block5_conv1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e82bdaf98&gt;</td>\n",
              "      <td>block5_conv2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x7f4e82be7fd0&gt;</td>\n",
              "      <td>block5_conv3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x7f4e82bf4470&gt;</td>\n",
              "      <td>block5_pool</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>&lt;keras.layers.core.Flatten object at 0x7f4e82baaef0&gt;</td>\n",
              "      <td>flatten_7</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        Layer Type  ... Layer Trainable\n",
              "0   <keras.engine.input_layer.InputLayer object at 0x7f4e83582978>  ...  False         \n",
              "1   <keras.layers.convolutional.Conv2D object at 0x7f4e835823c8>    ...  False         \n",
              "2   <keras.layers.convolutional.Conv2D object at 0x7f4e83195eb8>    ...  False         \n",
              "3   <keras.layers.pooling.MaxPooling2D object at 0x7f4e831975f8>    ...  False         \n",
              "4   <keras.layers.convolutional.Conv2D object at 0x7f4e83198a20>    ...  False         \n",
              "5   <keras.layers.convolutional.Conv2D object at 0x7f4e831a0198>    ...  False         \n",
              "6   <keras.layers.pooling.MaxPooling2D object at 0x7f4e82bf93c8>    ...  False         \n",
              "7   <keras.layers.convolutional.Conv2D object at 0x7f4e82c03f60>    ...  False         \n",
              "8   <keras.layers.convolutional.Conv2D object at 0x7f4e82c08b00>    ...  False         \n",
              "9   <keras.layers.convolutional.Conv2D object at 0x7f4e82c127f0>    ...  False         \n",
              "10  <keras.layers.pooling.MaxPooling2D object at 0x7f4e82c208d0>    ...  False         \n",
              "11  <keras.layers.convolutional.Conv2D object at 0x7f4e82c2dda0>    ...  False         \n",
              "12  <keras.layers.convolutional.Conv2D object at 0x7f4e82c335f8>    ...  False         \n",
              "13  <keras.layers.convolutional.Conv2D object at 0x7f4e82bc2438>    ...  False         \n",
              "14  <keras.layers.pooling.MaxPooling2D object at 0x7f4e82bcd3c8>    ...  False         \n",
              "15  <keras.layers.convolutional.Conv2D object at 0x7f4e82bda898>    ...  False         \n",
              "16  <keras.layers.convolutional.Conv2D object at 0x7f4e82bdaf98>    ...  False         \n",
              "17  <keras.layers.convolutional.Conv2D object at 0x7f4e82be7fd0>    ...  False         \n",
              "18  <keras.layers.pooling.MaxPooling2D object at 0x7f4e82bf4470>    ...  False         \n",
              "19  <keras.layers.core.Flatten object at 0x7f4e82baaef0>            ...  False         \n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3phxCC47kCYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import glob\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "# IMG_DIM = (150, 150)\n",
        "# train_files = glob.glob('Traning/*')\n",
        "\n",
        "# train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
        "# train_imgs = np.array(train_imgs)\n",
        "# train_imgs_scaled = train_imgs.astype('float32')\n",
        "\n",
        "# bottleneck_feature_example = vgg.predict(train_imgs_scaled[0:1:2])\n",
        "# print(bottleneck_feature_example.shape)\n",
        "# plt.imshow(bottleneck_feature_example[0][:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO18LFn8rZ2N",
        "colab_type": "code",
        "outputId": "8c98b7d5-1c3f-4b43-d848-07cd7513c9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "vgg.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        (None, 3, 150, 150)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 150, 150)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 150, 150)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 75, 75)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 75, 75)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 75, 75)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 128, 37, 37)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 256, 37, 37)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 256, 37, 37)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 256, 37, 37)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 256, 18, 18)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 512, 18, 18)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 512, 18, 18)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 512, 18, 18)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 512, 9, 9)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 512, 9, 9)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 512, 9, 9)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 512, 9, 9)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 512, 4, 4)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntRhNwmBbsUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# output = vgg.layers[-1].output\n",
        "# output = keras.layers.Flatten()(output)\n",
        "# vgg_model = Model(vgg.input, output)\n",
        "\n",
        "# vgg_model.trainable = False\n",
        "# for layer in vgg_model.layers:\n",
        "#     layer.trainable = False\n",
        "    \n",
        "# import pandas as pd\n",
        "# pd.set_option('max_colwidth', -1)\n",
        "# layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
        "# pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3wW5bR1tKSD",
        "colab_type": "code",
        "outputId": "cf52a67f-bcb6-46e8-bdf8-bea03ae783d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_dir = './drive/My Drive/DataSet150'\n",
        "train_dir = os.path.join(base_dir, 'Traning')\n",
        "validation_dir = os.path.join(base_dir, 'Evalution')\n",
        "test_dir = os.path.join(base_dir, 'Testing')\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 10\n",
        "\n",
        "def extract_features(directory, sample_count):\n",
        "    features = np.zeros(shape=(sample_count,512, 4, 4))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    generator = datagen.flow_from_directory(\n",
        "    directory,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "    i=0\n",
        "    for inputs_batch, labels_batch in generator:\n",
        "        features_batch = vgg.predict(inputs_batch)\n",
        "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "        i += 1\n",
        "        if i * batch_size >= sample_count:\n",
        "            break\n",
        "    return features, labels\n",
        "train_features, train_labels = extract_features(train_dir, 700)\n",
        "validation_features, validation_labels = extract_features(validation_dir, 500)\n",
        "test_features, test_labels = extract_features(test_dir, 500)\n",
        "\n",
        "train_features = np.reshape(train_features, (700, 4*4* 512))\n",
        "validation_features = np.reshape(validation_features, (500, 4*4* 512))\n",
        "test_features = np.reshape(test_features, (500, 4*4* 512))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 801 images belonging to 22 classes.\n",
            "Found 764 images belonging to 22 classes.\n",
            "Found 764 images belonging to 22 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H3jv6okvnZ-",
        "colab_type": "code",
        "outputId": "2fc146dc-6f06-434c-9306-5037e384b758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers \n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(22, activation='sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5, rho=0.9),\n",
        "              metrics=['accuracy'])          \n",
        "history = model.fit(train_features,to_categorical(train_labels),\n",
        "epochs=30,\n",
        "batch_size=10,\n",
        "validation_data=(validation_features, to_categorical(validation_labels)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Train on 700 samples, validate on 500 samples\n",
            "Epoch 1/30\n",
            "700/700 [==============================] - 3s 5ms/step - loss: 2.8768 - acc: 0.1657 - val_loss: 2.6365 - val_acc: 0.4260\n",
            "Epoch 2/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 2.4246 - acc: 0.5771 - val_loss: 2.1346 - val_acc: 0.8200\n",
            "Epoch 3/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 1.8890 - acc: 0.8071 - val_loss: 1.5649 - val_acc: 0.9160\n",
            "Epoch 4/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 1.3714 - acc: 0.8843 - val_loss: 1.1024 - val_acc: 0.9220\n",
            "Epoch 5/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 1.0054 - acc: 0.9029 - val_loss: 0.7868 - val_acc: 0.9500\n",
            "Epoch 6/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.7383 - acc: 0.9286 - val_loss: 0.5778 - val_acc: 0.9600\n",
            "Epoch 7/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5505 - acc: 0.9486 - val_loss: 0.4507 - val_acc: 0.9620\n",
            "Epoch 8/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.4272 - acc: 0.9671 - val_loss: 0.3632 - val_acc: 0.9640\n",
            "Epoch 9/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.3300 - acc: 0.9771 - val_loss: 0.3021 - val_acc: 0.9660\n",
            "Epoch 10/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.2747 - acc: 0.9771 - val_loss: 0.2620 - val_acc: 0.9700\n",
            "Epoch 11/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.2297 - acc: 0.9843 - val_loss: 0.2269 - val_acc: 0.9760\n",
            "Epoch 12/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.1797 - acc: 0.9857 - val_loss: 0.2015 - val_acc: 0.9680\n",
            "Epoch 13/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.1486 - acc: 0.9814 - val_loss: 0.1773 - val_acc: 0.9740\n",
            "Epoch 14/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.1165 - acc: 0.9957 - val_loss: 0.1636 - val_acc: 0.9720\n",
            "Epoch 15/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0919 - acc: 0.9986 - val_loss: 0.1484 - val_acc: 0.9720\n",
            "Epoch 16/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0906 - acc: 0.9957 - val_loss: 0.1361 - val_acc: 0.9800\n",
            "Epoch 17/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0672 - acc: 0.9986 - val_loss: 0.1303 - val_acc: 0.9720\n",
            "Epoch 18/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0579 - acc: 0.9986 - val_loss: 0.1196 - val_acc: 0.9780\n",
            "Epoch 19/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0507 - acc: 0.9957 - val_loss: 0.1090 - val_acc: 0.9760\n",
            "Epoch 20/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0400 - acc: 0.9986 - val_loss: 0.1045 - val_acc: 0.9760\n",
            "Epoch 21/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0434 - acc: 0.9971 - val_loss: 0.1096 - val_acc: 0.9780\n",
            "Epoch 22/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.0999 - val_acc: 0.9780\n",
            "Epoch 23/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.0928 - val_acc: 0.9800\n",
            "Epoch 24/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9760\n",
            "Epoch 25/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.0909 - val_acc: 0.9720\n",
            "Epoch 26/30\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9720\n",
            "Epoch 27/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0931 - val_acc: 0.9700\n",
            "Epoch 28/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9720\n",
            "Epoch 29/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0155 - acc: 0.9971 - val_loss: 0.0895 - val_acc: 0.9740\n",
            "Epoch 30/30\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0874 - val_acc: 0.9780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-TeavxBOzIG",
        "colab_type": "code",
        "outputId": "e6b2dc6f-b12e-48aa-9a24-7ce20443b640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhIQCXUQkJP4/D/zuHAi5WdsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSugiIlni/wMpL7/fe3+PMgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYXu5bx3csKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('drive/My Drive/DataSet150/feature_extraction_basic2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFhTqgREPQAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "model = models.Sequential()\n",
        "model.add(vgg)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(22, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aabC4DcFRkMz",
        "colab_type": "code",
        "outputId": "3452477f-f4d0-4722-edc7-6020650f02e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512, 4, 4)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 22)                5654      \n",
            "=================================================================\n",
            "Total params: 16,817,750\n",
            "Trainable params: 2,103,062\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwbNmyW8ckYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o1qk75oRn_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# print('This is the number of trainable weights '\n",
        "# 'before freezing the conv base:', len(model.trainable_weights))\n",
        "# #This is the number of trainable weights before freezing the conv base: 30\n",
        "# conv_base.trainable = False\n",
        "# print('This is the number of trainable weights '\n",
        "# 'after freezing the conv base:', len(model.trainable_weights))\n",
        "# #This is the number of trainable weights after freezing the conv base: 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSFtIqC2bZ25",
        "colab_type": "code",
        "outputId": "02d638c6-a4f0-4755-bf18-dce10b910162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                rescale=1./255,\n",
        "                rotation_range=40,\n",
        "                width_shift_range=0.2,\n",
        "                height_shift_range=0.2,\n",
        "                shear_range=0.2,\n",
        "                zoom_range=0.2,\n",
        "                horizontal_flip=True,\n",
        "                fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                train_path,\n",
        "                target_size=(150, 150),\n",
        "                batch_size=10,\n",
        "                class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "                validation_path,\n",
        "                target_size=(150, 150),\n",
        "                batch_size=10,\n",
        "                class_mode='categorical')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "                metrics=['acc'])\n",
        "\n",
        "history = model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=100,\n",
        "                epochs=10,\n",
        "                validation_data=validation_generator,\n",
        "                validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 801 images belonging to 22 classes.\n",
            "Found 764 images belonging to 22 classes.\n",
            "Epoch 1/10\n",
            "100/100 [==============================] - 425s 4s/step - loss: 3.0288 - acc: 0.0610 - val_loss: 2.9238 - val_acc: 0.1300\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 419s 4s/step - loss: 2.8508 - acc: 0.2370 - val_loss: 2.6847 - val_acc: 0.4534\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 424s 4s/step - loss: 2.5668 - acc: 0.5300 - val_loss: 2.3243 - val_acc: 0.7140\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 427s 4s/step - loss: 2.2022 - acc: 0.7181 - val_loss: 1.8685 - val_acc: 0.8644\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 421s 4s/step - loss: 1.7997 - acc: 0.8440 - val_loss: 1.4407 - val_acc: 0.9291\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 421s 4s/step - loss: 1.4324 - acc: 0.8920 - val_loss: 1.1204 - val_acc: 0.9320\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 419s 4s/step - loss: 1.1860 - acc: 0.8761 - val_loss: 0.8391 - val_acc: 0.9534\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 422s 4s/step - loss: 0.9344 - acc: 0.9320 - val_loss: 0.6891 - val_acc: 0.9615\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 421s 4s/step - loss: 0.7471 - acc: 0.9540 - val_loss: 0.5193 - val_acc: 0.9640\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 416s 4s/step - loss: 0.6109 - acc: 0.9540 - val_loss: 0.4332 - val_acc: 0.9595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dsx4tQabfk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ6nEj554xy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srm0QFFH5Djt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = True\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaDrZOVn5MUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "metrics=['acc'])\n",
        "history = model.fit_generator(\n",
        "train_generator,\n",
        "steps_per_epoch=100,\n",
        "epochs=10,\n",
        "validation_data=validation_generator,\n",
        "validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfSo2XnY5R17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o34_TL04bH53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}